{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Panal data analysis\n",
    "\n",
    "2 data structures are:\n",
    "\n",
    "a. Series\n",
    "\n",
    "    Properties:\n",
    "        a. 1-D\n",
    "        b. Homogenous\n",
    "        c. Broadcasting is allowed\n",
    "        d. Vectorization is allowed\n",
    "        \n",
    "    Creation:\n",
    "        a. using pd.Series() -> raw python data structure\n",
    "        b. We can import data from a file\n",
    "        c. We can create individual series from a dataframe.\n",
    "        \n",
    "    Metadata inspection:\n",
    "        a. ndim - shows dimensions\n",
    "        b. nbytes - shows memory size\n",
    "        c. dtype - shows data type\n",
    "        d. shape - shows shape\n",
    "        e. size - shows no. of elements\n",
    "        f. info - basic information about data - column\n",
    "        \n",
    "    Data inspection:\n",
    "        a. head - top 5 rows TOP/LIMIT\n",
    "        b. tail - bottom 5 rows\n",
    "        c. describe - Five Point summary in descriptive stats\n",
    "        d. quantile\n",
    "        e. count\n",
    "        f. min\n",
    "        g. max\n",
    "        h. mean\n",
    "        i. sum\n",
    "        \n",
    "        \n",
    "b. DataFrame\n",
    "    \n",
    "    Properties:\n",
    "        a. 2-D\n",
    "        b. Hetrogenous\n",
    "        c. Broadcasting is allowed\n",
    "        d. Vectorization is allowed \n",
    "    \n",
    "    Creation:\n",
    "        a. pd.DataFrame - raw python data structure\n",
    "        b. Reading table\n",
    "            I. from a file - text/csv/tsv/excel - read_csv, read_excel, read_parquet, read_json, read_xml, read_sas, read_sql - odbc connection\n",
    "            II. Connection with the database server is alsow possible\n",
    "            III. Web based data from a url\n",
    "        c. By combining multiple series.\n",
    "        \n",
    "     \n",
    "             \n",
    "    Metadata inspection:\n",
    "        a. ndim\n",
    "        b. nbytes\n",
    "        c. dtype\n",
    "        d. shape\n",
    "        e. size\n",
    "        f. info - basic information about data - column\n",
    "        g. columns\n",
    "        \n",
    "    Data inspection:\n",
    "        a. head - top 5 rows TOP/LIMIT\n",
    "        b. tail - bottom 5 rows\n",
    "        c. sample - random rows\n",
    "        d. describe - Five Point summary in descriptive stats\n",
    "        e. quantile\n",
    "        f. count\n",
    "        g. min\n",
    "        h. max\n",
    "        i. mean\n",
    "        j. sum\n",
    "        k. duplicated\n",
    "        l. value_counts\n",
    "        \n",
    "        \n",
    "        \n",
    "Indexes are 2 types:\n",
    "    a. (DI) Default indexes - Can't be changed. Their values will always be in between 0 and rows-1\n",
    "        -> will be accessible via slicing\n",
    "    b. UDI (Used defined index) - Can be changed according to the used.\n",
    "        -> can be provided directly\n",
    "\n",
    "Properties to address indexes:\n",
    ".loc - UDI - indexing/filtering is allowed\n",
    ".iloc - DI - indexing/filtering isn't possible with .iloc\n",
    "\n",
    "\n",
    "Common Data Operations:\n",
    "\n",
    "    1. Importing the data\n",
    "    2. Data Preparation/Data Cleaning/Data Wrangling/Data Munging\n",
    "        a. Understanding what needs to be done\n",
    "            1. Metadata based inspection\n",
    "            2. Data Inspection\n",
    "            3. EDA - Exploratory Data Analysis\n",
    "            \n",
    "        b. DF/Data Changes:\n",
    "        \n",
    "            a. Structural changes\n",
    "                1. Subsetting of data -> Selection of a subset of columns\n",
    "                2. Reordering the variables\n",
    "                3. Renaming the columns\n",
    "                4. Data Type Conversions\n",
    "                \n",
    "            b. Updation of data\n",
    "                1. Filter\n",
    "                2. Sorting\n",
    "                3. Duplicates\n",
    "                4. Outliers\n",
    "                    \n",
    "                    a. Detection of outliers\n",
    "                        1. Percentile rule\n",
    "                        2. IQR Rule - Interquartile rule\n",
    "                        3. z-score rule\n",
    "                    b. Treatment of outliers\n",
    "                        1. Percentile rule\n",
    "                        2. IQR Rule - Interquartile rule\n",
    "                        3. z-score rule\n",
    "                5. Missing values\n",
    "                6. Summaries\n",
    "                7. Combining the datasets\n",
    "                    a. Append\n",
    "                    b. Merge (Join)\n",
    "                8. Groups & Bins\n",
    "                9. Functions (UDF - User Defined functions)\n",
    "     3. BI - Business Intelligence (Reports/Dashboards)\n",
    "     4. Predictive Analysis\n",
    "     5. Prescriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
